{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <h1>æ¬¢è¿æ¥åˆ° SSCMA åœ¨ Google Colab çš„ç¤ºä¾‹åŸ¹è®­ ğŸ”¥</h1>\n",
    "  <a href=\"https://sensecraftma.seeed.cc/\" target=\"_blank\"><img width=\"20%\" src=\"https://sensecraftma.seeed.cc/images/SSCMA-Hero.png\"></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection - Swift-YOLO\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seeed-studio/sscma-model-zoo/blob/refactor-auto-generate/notebooks/en/Face_Detection_Swift-YOLO_192.ipynb)\n",
    "\n",
    "**ç‰ˆæœ¬:** 1.0.0\n",
    "\n",
    "**ä»»åŠ¡:** Object Detection\n",
    "\n",
    "**ç®—æ³•:** [Swift-YOLO](configs/yolov5/yolov5_tiny_1xb16_300e_coco.py)\n",
    "\n",
    "**æ•°æ®é›†:** [Face](https://universe.roboflow.com/detection-kgpie/face-detection-j0igc)\n",
    "\n",
    "**ç±»åˆ«:** `Face`\n",
    "\n",
    "![Face Detection](https://files.seeedstudio.com/sscma/static/detection_face.png)\n",
    "\n",
    "The model is a Swift-YOLO model trained on the Face dataset. The model can detect faces in images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸å‡†å¤‡å·¥ä½œ\n",
    "å…‹éš† [ä»“åº“](https://github.com/Seeed-Studio/SSCMA) å¹¶å®‰è£…ä¾èµ–é¡¹ã€‚\n",
    "### é…ç½®SSCMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Seeed-Studio/SSCMA.git   #å…‹éš†ä»“åº“\n",
    "%cd SSCMA\n",
    "!. ./scripts/setup_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%mkdir -p Face_Detection_Swift-YOLO_192 \n",
    "!wget -c https://files.seeedstudio.com/sscma/model_zoo/detection/models/yolov5/Face/yolov5_tiny_1xb16_300e_coco_sha1_f2a3f61a271c467748e26f0fd6fdd82d740512ff.pth -O Face_Detection_Swift-YOLO_192/pretrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{download_pretrained_model}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%mkdir -p Face_Detection_Swift-YOLO_192/dataset \n",
    "!wget -c https://universe.roboflow.com/ds/hK8PvFlIZ5?key=LxpaoUhp5i -O Face_Detection_Swift-YOLO_192/dataset.zip \n",
    "!unzip -q Face_Detection_Swift-YOLO_192/dataset.zip -d Face_Detection_Swift-YOLO_192/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{download_dataset}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!sscma.train configs/yolov5/yolov5_tiny_1xb16_300e_coco.py \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Face_Detection_Swift-YOLO_192 \\\n",
    "    num_classes=1 \\\n",
    "    epochs=10  \\\n",
    "    height=192 \\\n",
    "    width=192 \\\n",
    "    data_root=Face_Detection_Swift-YOLO_192/dataset/ \\\n",
    "    load_from=Face_Detection_Swift-YOLO_192/pretrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{train_model}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "with open('Face_Detection_Swift-YOLO_192/last_checkpoint', 'r') as f:\n",
    "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sscma.export configs/yolov5/yolov5_tiny_1xb16_300e_coco.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
    "    work_dir=Face_Detection_Swift-YOLO_192 \\\n",
    "    num_classes=1 \\\n",
    "    epochs=10  \\\n",
    "    height=192 \\\n",
    "    width=192 \\\n",
    "    data_root=Face_Detection_Swift-YOLO_192/dataset/ \\\n",
    "    load_from=Face_Detection_Swift-YOLO_192/pretrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{export_model}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“è¯„ä¼°æ¨¡å‹\n",
    "å¯¼å‡ºæ¨¡å‹åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ `inference.py` è„šæœ¬è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚\n",
    "\n",
    "```bash\n",
    "python3 tools/inference.py \\\n",
    "    \"<CONFIG_FILE_PATH>\" \\\n",
    "    \"<CHECKPOINT_FILE_PATH>\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!sscma.inference configs/yolov5/yolov5_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Face_Detection_Swift-YOLO_192 \\\n",
    "    num_classes=1 \\\n",
    "    epochs=10  \\\n",
    "    height=192 \\\n",
    "    width=192 \\\n",
    "    data_root=Face_Detection_Swift-YOLO_192/dataset/ \\\n",
    "    load_from=Face_Detection_Swift-YOLO_192/pretrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{eval_model_pth}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!sscma.inference configs/yolov5/yolov5_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Face_Detection_Swift-YOLO_192 \\\n",
    "    num_classes=1 \\\n",
    "    epochs=10  \\\n",
    "    height=192 \\\n",
    "    width=192 \\\n",
    "    data_root=Face_Detection_Swift-YOLO_192/dataset/ \\\n",
    "    load_from=Face_Detection_Swift-YOLO_192/pretrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{eval_model_tflite_flot32}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!sscma.inference configs/yolov5/yolov5_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Face_Detection_Swift-YOLO_192 \\\n",
    "    num_classes=1 \\\n",
    "    epochs=10  \\\n",
    "    height=192 \\\n",
    "    width=192 \\\n",
    "    data_root=Face_Detection_Swift-YOLO_192/dataset/ \\\n",
    "    load_from=Face_Detection_Swift-YOLO_192/pretrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sscma.inference config.py last_float32.tflte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!sscma.inference configs/yolov5/yolov5_tiny_1xb16_300e_coco.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Face_Detection_Swift-YOLO_192 \\\n",
    "    num_classes=1 \\\n",
    "    epochs=10  \\\n",
    "    height=192 \\\n",
    "    width=192 \\\n",
    "    data_root=Face_Detection_Swift-YOLO_192/dataset/ \\\n",
    "    load_from=Face_Detection_Swift-YOLO_192/pretrain.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{eval_model_tflite_int8}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%ls -lh Face_Detection_Swift-YOLO_192/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{show_result}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ„Ÿè°¢æ‚¨å°è¯• SSCMA ğŸ‰\n",
    "\n",
    "æ­å–œæ‚¨å®Œæˆæœ¬æ•™ç¨‹ã€‚å¦‚æœæ‚¨å¯¹æ›´å¤šåº”ç”¨åœºæ™¯æˆ–æˆ‘ä»¬çš„é¡¹ç›®æ„Ÿå…´è¶£ï¼Œè¯·åœ¨ GitHub ä¸Šç»™ [SSCMA](https://github.com/Seeed-Studio/SSCMA) åŠ ä¸ªæ˜Ÿ âœ¨ã€‚\n",
    "\n",
    "å¦‚æœæ‚¨å¯¹æœ¬æ•™ç¨‹æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶[æäº¤é—®é¢˜](https://github.com/Seeed-Studio/SSCMA/issues)ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edgelab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
