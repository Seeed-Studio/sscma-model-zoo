{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <h1>欢迎来到 ModelAssitant 的 Notebook 示例培训 🔥</h1>\n",
    "  <a href=\"https://sensecraftma.seeed.cc/\" target=\"_blank\"><img width=\"20%\" src=\"https://files.seeedstudio.com/sscma/docs/images/SSCMA-Hero.png\"></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Person Classification - MobileNetV2 0.35 Rep\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/seeed-studio/sscma-model-zoo/blob/main/notebooks/en/Person_Classification_MobileNetV2_0.35_Rep_32.ipynb)\n",
    "\n",
    "**版本:** 1.0.0\n",
    "\n",
    "**任务:** Image Classification\n",
    "\n",
    "**算法:** [MobileNetV2 0.35 Rep](configs/classification/mobnetv2_0.35_rep_1bx16_300e_custom.py)\n",
    "\n",
    "**数据集:** [VWW](https://github.com/Mxbonn/visualwakewords)\n",
    "\n",
    "**类别:** `Not a person`, `Person`\n",
    "\n",
    "![Person Classification](https://files.seeedstudio.com/sscma/static/person_cls.png)\n",
    "\n",
    "The model is a vision model designed for person classification. It utilizes the [SSCMA](https://github.com/Seeed-Studio/ModelAssistant) training and employs the MobileNetV2 (0.35) Rep algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚙️准备工作\n",
    "克隆 [仓库](https://github.com/Seeed-Studio/ModelAssistant) 并安装依赖项。\n",
    "### 配置SSCMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切换到python3.10\n",
    "!update-alternatives --set python3 /usr/bin/python3.10\n",
    "!apt install python3-pip\n",
    "# Ethos-U-Vela 需要通过以下命令安装\n",
    "!git clone https://review.mlplatform.org/ml/ethos-u/ethos-u-vela.git\n",
    "%cd ethos-u-vela\n",
    "!pip install .\n",
    "%cd ..\n",
    "!git clone https://github.com/Seeed-Studio/ModelAssistant.git -b 2.0.0  #克隆仓库\n",
    "%cd ModelAssistant\n",
    "!. ./scripts/setup_colab.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载模型权重文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir -p Person_Classification_MobileNetV2_0.35_Rep_32 \n",
    "!wget -c https://files.seeedstudio.com/sscma/model_zoo/classification/person/mobilenetv2_0.35rep_vww32_float32_sha1_c0bb3413912614cb90492eb4c2fbfbf6d3005874.pth -O Person_Classification_MobileNetV2_0.35_Rep_32/pretrain.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir -p Person_Classification_MobileNetV2_0.35_Rep_32/dataset \n",
    "!wget -c https://universe.roboflow.com/ds/rvZt8qZfBp?key=WDJI0KBhlY -O Person_Classification_MobileNetV2_0.35_Rep_32/dataset.zip \n",
    "!unzip -q Person_Classification_MobileNetV2_0.35_Rep_32/dataset.zip -d Person_Classification_MobileNetV2_0.35_Rep_32/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀使用 SSCMA 训练模型\n",
    "所有的训练参数都在 `config.py` 文件中，您可以更改这些参数以训练自己的模型。\n",
    "\n",
    "下面是一些常见参数的解释。您还可以参考[文档](https://sensecraftma.seeed.cc/tutorials/config)获取更多详情。\n",
    "- `data_root` - 数据集路径。\n",
    "- `epochs` - 训练周期数。**这里为了方便演示，我们将其设置为 10**。\n",
    "- `batch_size` - 批次大小。\n",
    "- `height` - 图像高度。\n",
    "- `width` - 图像宽度。\n",
    "- `load_from` - 预训练模型路径。\n",
    "- `num_classes` - 数据集类别数。\n",
    "\n",
    "您可以使用 `--cfg-options` 参数覆盖 `config.py` 文件中的参数。\n",
    "```bash\n",
    "# 示例\n",
    "sscma.train config.py --cfg-options data_root=./datasets/test_dataset epochs=10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sscma.train configs/classification/mobnetv2_0.35_rep_1bx16_300e_custom.py \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Person_Classification_MobileNetV2_0.35_Rep_32 \\\n",
    "    num_classes=2 \\\n",
    "    epochs=10  \\\n",
    "    height=32 \\\n",
    "    width=32 \\\n",
    "    data_root=Person_Classification_MobileNetV2_0.35_Rep_32/dataset/ \\\n",
    "    load_from=Person_Classification_MobileNetV2_0.35_Rep_32/pretrain.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦导出模型\n",
    "训练完成后，您可以将模型导出为部署所需的格式。目前 SSCMA 支持导出到 ONNX 和 TensorFlow Lite 格式。\n",
    "您还可以参考[文档](https://sensecraftma.seeed.cc/tutorials/export/overview)获取更多详情。\n",
    "```bash\n",
    "python3 tools/export.py \\\n",
    "    \"<CONFIG_FILE_PATH>\" \\\n",
    "    \"<CHECKPOINT_FILE_PATH>\" \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open('Person_Classification_MobileNetV2_0.35_Rep_32/last_checkpoint', 'r') as f:\n",
    "\tos.environ['CHECKPOINT_FILE_PATH'] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sscma.export configs/classification/mobnetv2_0.35_rep_1bx16_300e_custom.py $CHECKPOINT_FILE_PATH --cfg-options  \\\n",
    "    work_dir=Person_Classification_MobileNetV2_0.35_Rep_32 \\\n",
    "    num_classes=2 \\\n",
    "    epochs=10  \\\n",
    "    height=32 \\\n",
    "    width=32 \\\n",
    "    data_root=Person_Classification_MobileNetV2_0.35_Rep_32/dataset/ \\\n",
    "    load_from=Person_Classification_MobileNetV2_0.35_Rep_32/pretrain.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝评估模型\n",
    "导出模型后，您可以使用 `inference.py` 脚本评估模型的性能。\n",
    "\n",
    "```bash\n",
    "python3 tools/inference.py \\\n",
    "    \"<CONFIG_FILE_PATH>\" \\\n",
    "    \"<CHECKPOINT_FILE_PATH>\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估 PyTorch 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sscma.inference configs/classification/mobnetv2_0.35_rep_1bx16_300e_custom.py ${CHECKPOINT_FILE_PATH%.*}.pth \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Person_Classification_MobileNetV2_0.35_Rep_32 \\\n",
    "    num_classes=2 \\\n",
    "    epochs=10  \\\n",
    "    height=32 \\\n",
    "    width=32 \\\n",
    "    data_root=Person_Classification_MobileNetV2_0.35_Rep_32/dataset/ \\\n",
    "    load_from=Person_Classification_MobileNetV2_0.35_Rep_32/pretrain.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估 ONNX 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sscma.inference configs/classification/mobnetv2_0.35_rep_1bx16_300e_custom.py ${CHECKPOINT_FILE_PATH%.*}_float32.onnx \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Person_Classification_MobileNetV2_0.35_Rep_32 \\\n",
    "    num_classes=2 \\\n",
    "    epochs=10  \\\n",
    "    height=32 \\\n",
    "    width=32 \\\n",
    "    data_root=Person_Classification_MobileNetV2_0.35_Rep_32/dataset/ \\\n",
    "    load_from=Person_Classification_MobileNetV2_0.35_Rep_32/pretrain.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估 TFLite Float32 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sscma.inference configs/classification/mobnetv2_0.35_rep_1bx16_300e_custom.py ${CHECKPOINT_FILE_PATH%.*}_float32.tflite \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Person_Classification_MobileNetV2_0.35_Rep_32 \\\n",
    "    num_classes=2 \\\n",
    "    epochs=10  \\\n",
    "    height=32 \\\n",
    "    width=32 \\\n",
    "    data_root=Person_Classification_MobileNetV2_0.35_Rep_32/dataset/ \\\n",
    "    load_from=Person_Classification_MobileNetV2_0.35_Rep_32/pretrain.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估 TFLite INT8 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sscma.inference configs/classification/mobnetv2_0.35_rep_1bx16_300e_custom.py ${CHECKPOINT_FILE_PATH%.*}_int8.tflite \\\n",
    "--cfg-options  \\\n",
    "    work_dir=Person_Classification_MobileNetV2_0.35_Rep_32 \\\n",
    "    num_classes=2 \\\n",
    "    epochs=10  \\\n",
    "    height=32 \\\n",
    "    width=32 \\\n",
    "    data_root=Person_Classification_MobileNetV2_0.35_Rep_32/dataset/ \\\n",
    "    load_from=Person_Classification_MobileNetV2_0.35_Rep_32/pretrain.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖模型部署\n",
    "在进行模型训练，评估和导出后，您可以将模型部署到您的设备上。您可以参考[文档](https://sensecraftma.seeed.cc/deploy/overview)获取更多详情。\n",
    "你可以在下面的文件夹中获取所有的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -lh Person_Classification_MobileNetV2_0.35_Rep_32/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 感谢您尝试 SSCMA 🎉\n",
    "\n",
    "恭喜您完成本教程。如果您对更多应用场景或我们的项目感兴趣，请在 GitHub 上给 [ModelAssistant](https://github.com/Seeed-Studio/ModelAssistant) 加个星 ✨。\n",
    "\n",
    "如果您对本教程有任何问题，请随时[提交问题](https://github.com/Seeed-Studio/ModelAssistant/issues)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edgelab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
